{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#installs\n",
        "!pip install langchain openai stability-sdk pillow\n",
        "!pip install langchain-community langchain-core\n",
        "!pip install wikipedia-api transformers\n",
        "!pip install wikipedia\n",
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "TXkV1D7beqYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import wikipediaapi\n",
        "from transformers import pipeline, CLIPProcessor, CLIPModel, BlipProcessor, BlipForConditionalGeneration\n",
        "import math\n",
        "import json\n",
        "import io\n",
        "import os\n",
        "import warnings\n",
        "import random\n",
        "import torch\n",
        "import re\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from stability_sdk import client\n",
        "import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "import langchain\n",
        "import openai\n",
        "import stability_sdk\n",
        "import wikipedia"
      ],
      "metadata": {
        "id": "lle9O7h8erBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUL7R2vqekFQ"
      },
      "outputs": [],
      "source": [
        "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "def generate_caption(image, prompt):\n",
        "    inputs = blip_processor(images=image, return_tensors=\"pt\", prompt=prompt)\n",
        "    out = blip_model.generate(**inputs)\n",
        "    caption = blip_processor.decode(out[0], skip_special_tokens=True)\n",
        "    return caption\n",
        "\n",
        "def calculate_similarity(text1, text2):\n",
        "    text1_tokens = clip_processor(text=text1, return_tensors=\"pt\", padding=True, max_length=77, truncation=True)\n",
        "    text2_tokens = clip_processor(text=text2, return_tensors=\"pt\", padding=True, max_length=77, truncation=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        text1_features = clip_model.get_text_features(**text1_tokens)\n",
        "        text2_features = clip_model.get_text_features(**text2_tokens)\n",
        "\n",
        "    similarity = torch.nn.functional.cosine_similarity(text1_features, text2_features, dim=-1)\n",
        "    return similarity.item()\n",
        "\n",
        "def combine_with_context(description, context):\n",
        "    return f\"{context} {description}\"\n",
        "\n",
        "def load_panels(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        original_panels = json.load(f)\n",
        "    return original_panels\n",
        "\n",
        "wikipedia_context = summary\n",
        "\n",
        "panel_file_path = 'panels.json'\n",
        "original_panels = load_panels(panel_file_path)\n",
        "\n",
        "generated_captions = []\n",
        "for panel in original_panels:\n",
        "    image_path = f\"panel-{panel['number']}.png\"\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    combined_prompt = combine_with_context(panel['description'], wikipedia_context)\n",
        "\n",
        "    combined_prompt = combined_prompt[:512]\n",
        "\n",
        "    caption = generate_caption(image, combined_prompt)\n",
        "    generated_captions.append(caption)\n",
        "\n",
        "similarities = []\n",
        "for original, generated in zip(original_panels, generated_captions):\n",
        "    similarity = calculate_similarity(original['description'], generated)\n",
        "    similarities.append(similarity)\n",
        "    print(f\"Original: {original['description']}\\nGenerated: {generated}\\nSimilarity: {similarity}\\n\")\n",
        "\n",
        "average_similarity = sum(similarities) / len(similarities)\n",
        "print(f\"Average similarity: {average_similarity}\")\n"
      ]
    }
  ]
}