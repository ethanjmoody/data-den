# What happens when pilgrims attend the Hajj pilgrimage to Mecca? 

```{problem_description}
What happens when a diverse set of people are brought together toward a common purpose? Maybe it brings people together, or maybe instead it highlights the differences between groups.  [Clingingsmith, Khwaja and Kremer (2009)](https://dash.harvard.edu/handle/1/3659699) investigate the question. by asking Pakistani nationals to provide information about their views about people from other nations. 

The random assignment and data is collected in the following way (detailed in the paper): 

- Pakistani nationals apply for a chance to attend the Hajj at a domestic bank. Saudi Arabia agreed in the time period of the study (2006) to grant 150,000 visas. 
- Of the 135,000 people who applied for a visa, 59% of those who applied were successful. 
- The remainder of the visas were granted under a different allocation method that was not randomly assigned, and so this experiment cannot provide causal evidence about other allocation mechanisms. 
- Among the 135,000 who apply, the authors conduct a random sample and survey about these respondents views about others. 

Using the data collected by the authors, test, using randomization infernece, whether there is a change in beliefs about others as a result of attending the Hajj. 

- Use, as your primary outcome the `views` variable. This variable is a column-sum of each respondents views toward members of other countries. 
- Use, as your treatment feature `success`. This variable encodes whether the respondent successfully attended the Hajj. 
```

```{r load hajj data}
d <- fread("../data/clingingsmith_2009.csv")
```

## State a null hypothesis
State the sharp-null hypothesis that you will be testing.  

```{r, include = TRUE}
# Answer provided in narrative form below
```

**Answer:** The sharp null hypothesis holds that the treatment effect is zero for all subjects (i.e., the potential outcomes to treatment and control are equivalent for each and every individual). In the context of this test, the sharp null hypothesis that we're testing is that, *for every individual respondent, there is no change in beliefs about members of other countries as a result of successfully attending the Hajj* (that is, every respondent's potential outcome to control --- their views toward members of other countries after *not* attending the Hajj --- is the same as their potential outcome to treatment --- their views toward members of other countries after attending the Hajj).

## Group by average
Using `data.table`, group the data by `success` and report whether views toward others are generally more positive among lottery winners or lottery non-winners. This answer should be of the form `d[ , .(mean_views = ...), keyby = ...]` where you have filled in the `...` with the appropriate functions and variables. 

```{r actual hajj ate, include = TRUE}
# the result should be a data.table with two columns and two rows

# Compute mean `views` across `success` groups (control and treatment)
hajj_group_mean <- d[, .(mean_views = mean(views)), keyby = success] 

# from the `hajj_group_mean` produce a single, numeric vector that is the ate. 
# check that it is numeric using `class(hajj_ate)`

# Compute ATE based on difference in `success` group means of `views`
hajj_ate        <- hajj_group_mean[success == 1, mean_views] -
                   hajj_group_mean[success == 0, mean_views]

# Display class for `hajj_ate` to check for numeric result
class(hajj_ate)
```

**Answer:** The `hajj_group_mean` (i.e., mean `views` across each `success` group) is displayed in the table below:

`r kable(hajj_group_mean)`

Based on this data, the `hajj_ate` is equal to `r hajj_ate`. Both this value and the group means above indicate that *views toward others are generally more positive among lottery winners (Hajj attendees) than lottery non-winners.*

```{problem_description}
But is this a "meaningful" difference? Or, could a difference of this size have arisen from an "unlucky" randomization? Conduct 10,000 simulated random assignments under the sharp null hypothesis to find out. (Do not just copy the code from the async, think about how to write this yourself.) 
```

```{r hajj randomization inference, include=TRUE}
## do your work to conduct the randomization inference here.
## as a reminder, RI will randomly permute / assign the treatment variable
## and recompute the test-statistic (i.e. the mean difference) under each permutation
## this should be a numeric vector that has a length equal to the number 
## of RI permutations you ran

# Create randomization inference function for modular and reusable code
ri <- function(permutations = 10000) {
  
  # Create vector to store test-statistic (ATE) under each permutation
  hajj_ate_vector <- NA
  
  # success_group1  <- NA   # For checking treatment group proportions (TGP)
  # success_group0  <- NA   # For checking control group proportions (CGP)
  
  # Simulate 10000 random permutations of treatment assignment
  for(perm in 1:permutations) { 
    
    # Add computed test-statistics to vector after treatment randomization
    hajj_ate_vector[perm] <- d[, .(mean_views = mean(views)), 
                               keyby = .(sample(success))][, diff(mean_views)]
    
    # success_group1[perm]  <- d[, sum(success == 1)]  # For TGP
    # success_group0[perm]  <- d[, sum(success == 0)]  # For CGP
  }
  
  # Return vector of test-statistics
  return(hajj_ate_vector)
  
  # return(list(hajj_ate_vector, success_group1, success_group0))  # For TGP/CGP
}

# Run randomization inference function with 10000 permutations 
hajj_ri_distribution <- ri(10000)
```

## Randomization inference: At least as large
C. How many of the simulated random assignments generate an estimated ATE that is at least as large as the actual estimate of the ATE? Conduct your work in the code chunk below, saving the results into `hajj_count_larger`, but also support your coding with a narrative description. In that narrative description (and throughout), use R's "inline code chunks" to write your answer consistent with each time your run your code.  

```{r hajj one-tailed count, include = TRUE}
# length 1 numeric vector from comparison of `hajj_ate` and `hajj_ri_distribution`

# Determine number of randomizations with an ATE >= est.ATE
hajj_count_larger <- as.numeric(sum(hajj_ri_distribution >= hajj_ate))

# Display result
hajj_count_larger
```

**Answer:** Only `r hajj_count_larger` of the `r length(hajj_ri_distribution)` permutations/random assignments generated an estimated ATE that is at least as large as the actual estimated ATE of `r hajj_ate`.

## Randomization inference: one-sided p-value
If there are `hajj_count_larger` (`r hajj_count_larger`) randomizations that are larger than `hajj_ate` (`r hajj_ate`), what is the *one-tailed* p-value? Both write the code in the following chunk, and include a narrative description of the result following your code.  

```{r hajj one-tailed p-value, include=TRUE}
# length 1 numeric vector

# Determine one-tailed p-value corresponding to `hajj_count_larger` result
hajj_one_tailed_p_value <- as.numeric(
  hajj_count_larger / length(hajj_ri_distribution))

# Display result
hajj_one_tailed_p_value
```

**Answer:** The one-tailed p-value is `r hajj_one_tailed_p_value`, which suggests that only a very small proportion of randomizations (i.e., only `r hajj_count_larger` of the `r length(hajj_ri_distribution)` permutations/random assignments) are at least as large or larger than the actual estimated ATE of `r hajj_ate`. This result indicates that the original difference in means we calculated for `views` across `success` groups is *meaningful* and not likely to arise just by chance alone (or by an "unlucky" randomization) under the assumption of the sharp null hypothesis.

## Randomization inference: two-sided p-value
Now, conduct a similar test, but for a two-sided p-value. You can either use two tests, one for larger than and another for smaller than; or, you can use an absolute value (`abs`). Both write the code in the following chunk, and include a narrative description of the result following your code. 

```{r hajj two-tailed p-value, include=TRUE}
# length 1 numeric vector

# Determine number of randomizations with an ATE <= -1 * est. ATE
hajj_count_smaller <- as.numeric(sum(hajj_ri_distribution <= (-1 * hajj_ate)))

# Determine number of randomizations with an ATE at least as extreme as est. ATE
hajj_count_extreme <- as.numeric(sum(hajj_count_larger, hajj_count_smaller))

# Determine two-tailed p-value corresponding to `hajj_count_extreme` result
hajj_two_tailed_p_value <- as.numeric(
  hajj_count_extreme / length(hajj_ri_distribution))

# Display result
hajj_two_tailed_p_value
```

**Answer:** The two-tailed p-value is `r hajj_two_tailed_p_value`, which --- like the one-tailed p-value --- suggests that only a very small proportion of randomizations (i.e., only `r hajj_count_extreme` of the `r length(hajj_ri_distribution)` permutations/random assignments) are at least as extreme as the actual estimated ATE of `r hajj_ate`. This result also indicates that the original difference in means we calculated for `views` across `success` groups is *meaningful* and not likely to arise just by chance alone (or by an "unlucky" randomization) under the assumption of the sharp null hypothesis.
