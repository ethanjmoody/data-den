# Think about Treatment Effects 

Throughout this course we have focused on the average treatment effect. *Why* we are concerned about the average treatment effect. What is the relationship between an ATE, and some individuals' potential outcomes? Make the strongest case you can for why this is a *good* measure.

**Answer:** The average treatment effect (ATE) is a fundamental concept in field experimentation. In "potential outcomes" notation, the ATE measures the arithmetic difference between (1) the expected value (average) of experimental subjects' potential outcomes to treatment and (2) the expected value (average) of experimental subjects' potential outcomes to control (i.e., $ATE = E[Y_i(1)] - E[Y_i(0)]$, or $ATE = \frac{1}{N} \sum_{i=1}^{N} \tau_i$, where $\tau_i$ represents the treatment effect $Y_i(1) - Y_i(0)$ of the $i$th subject). Ideally, to measure treatment effects, we'd have access to both (1) and (2) for every experimental subject. However, in the real world, this isn't possible; we can only observe *either* (1) *or* (2) for each subject based on whether they're exposed to treatment or to control. Fortunately, to overcome this obstacle, we can leverage a procedure called random assignment to randomly assign all experimental subjects to either the treatment or control condition. If this assignment procedure is truly random, it ensures that the make-up of both groups of subjects is identical across all their underlying characteristics (eliminating all unobserved heterogeneity), and it allows us to attribute any change in outcomes for the treatment group relative to the control group to the treatment itself. This provides a justification for deeming these groups to be equivalent prior to the administration of treatment, and for comparing *averages* across the groups to determine the effect of a treatment. Because of their pre-treatment equivalence, we can say that if treatment were *not* administered to those in the treatment group, the average value for the outcome variable across the treatment group should be statistically identical to the average value for the outcome variable across the control group. Thus, we can also say that any difference observed between these group-average outcome values *post-treatment* represents the ATE.

It's important to note that any individual subject's potential outcome to treatment or to control might differ from the average outcome across their membership group (treatment/control). In fact, the "average" prefix in "average treatment effect" (ATE) recognizes the presence of variability in the underlying individual subject-level outcomes. However, using the ATE as a summary measure of an experiment's treatment effect has several key advantages over merely invoking the distribution of individual subject-level treatment effects. First, the ATE represents a single number that is simple to communicate and easily understandable. It's far less cumbersome to cite a single number when reporting the outcome of an experiment than a whole range (distribution) of numbers, which improves the communicability of experimental results. The ATE helps anchor both experimenters and their target audience on a particular value that describes the overall effect of a treatment, rather than focus their attention on a wide range of possible effects across all unique experimental subjects (e.g., the minimum effect, the maximum effect, the effect at the 25th percentile, the effect at the 75th percentile, etc.). Second, the ATE is something that can be easily tested for reproducibility. One of the hallmarks of any good experiment --- in terms of its design and measurement --- is its ability to be reproduced or corroborated by a follow-up experiment. If the ATE were tossed aside in favor of the distribution of individual subject-level outcomes, would any experiment be considered truly reproducible unless the follow-up study had the exact same number of participants or very closely matched the distribution of effects from the original study? Perhaps that question verges on hyperbole, but more fairly, comparing ATEs across experiments allows for a more rapid/efficient and reliable test of reproducibility than comparing individualized outcomes, and reproducible experiments --- as well as reproducibility tests --- advance the cause of scientific progress. Third, the ATE is a generalized measure of a given treatment's effect, which helps set expectations for researchers, subjects, decision-makers, and the general population around the treatment's impact. While the ATE may not describe the unique effect that each individual subject experiences, it seeks to offer a fair estimate for the effect of the treatment across this diverse group of subjects so that the treatment's impact is understood *in general*. Business professionals might use this info to design a new product or enhancement; social scientists or research practitioners might use this info to build on prior research; politicians or economists might use this info to implement new policy; and members of the general public might use this info to make a decision about whether to take or not take an action, a medical supplement, etc. Fourth, the ATE is helpful for prioritizing or stack-ranking different treatments and making decisions around which to pursue. A researcher might test many similar treatments (e.g., a drug containing 1000mg of a substance vs. 100mg, or a message with many typos vs. none, or a visual stimulus that lasts 20 seconds vs. 5 seconds, etc.) for a particular use-case and need to rank them on the basis of affordability, availability, feasibility, public safety, etc. Having an ATE for each treatment dosage-level or scenario would allow them to quickly analyze these considerations against their associated experimental outcomes/impacts, draw comparisons, and make informed decisions. For these reasons, although the ATE isn't a perfect representation of every individualized outcome within an experiment, it provides a *good* measure of the effect of any given treatment --- one that's simple to communicate and understand, reproducible, generalizable, comparable, and practical.
