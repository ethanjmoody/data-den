{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f465500",
   "metadata": {},
   "source": [
    "# Gourmet Meals Business -- SQL Project (Part 2.1 - Product Mapping)\n",
    "\n",
    "Author: **Ethan Moody**\n",
    "\n",
    "Date: **October 2022**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d2979",
   "metadata": {},
   "source": [
    "### Business Case\n",
    "\n",
    "Assume you are a data engineer working closely with the data science team at Agile Gourmet Meals (AGM).\n",
    "\n",
    "AGM executives are considering adding a delivery option, with the hopes of increasing sales, growing the customer base, and increasing profitability.   \n",
    "\n",
    "Management decided to do a proof of concept (POC) in the form of a three month trial run using one delivery service at the Berkeley store. They have called upon the data science team to help with this effort. In turn, the data science team has asked for your help in the data engineering aspects of the POC.\n",
    "\n",
    "Management chose Peak Deliveries primarily because it's a newer operation with a model that takes a percentage cut of the product pricing instead of charging customers a delivery fee. Peak's cut is 18%. So, for each $12 meal, that equates to approximately $2.16. Customers may tip the delivery driver if they wish. AGM is not given any visibility into customer tips. (Peak is protecting its data on good tippers.) Peak has an outstanding reputation for great, fast, and efficient deliveries, with excellent customer service. Peak will only deliver to zip codes within a 5 mile radius of the store.\n",
    "\n",
    "Integration with any third party sales channel always comes with its challenges. For large companies, like McDonalds, the delivery companies are willing to integrate and modify their computer systems as needed to get the contract. For small companies, like AGM, one of your only options is to use Peak's API to send and receive data. However, that would require you to write a lot of code, which management does not want to spend money on until the POC has proven successful. As an alternative, Peak can provide you with a JSON file at the end of each day with detailed sales information for that day. Management has decided to go with the daily JSON option for now for the POC. \n",
    "\n",
    "For products, AGM will enter products into Peak's system. Peak will assign an ID in their system to the product. You will need to create a mapping table to map Peak's IDs to AGM's IDs. In AGM's case, all products cost $12 and are tax exempt. AGM will mark them as exempt from sales tax.\n",
    "\n",
    "Regarding the customer list, AGM does not want to give out their full customer list to third parties.  Customers will have to sign up with Peak, either using the website, the app, or by telephone.  AGM executives anticipate and understand that the trade off to not giving them the customer list is that you will probably have to validate and/or cleanse the customer data. Peak will assign their customer ID to each customer.\n",
    "\n",
    "In this POC, you will focus on only 1 store: the Berkeley store. Peak will create a pickup location for the store and assign their own location ID to it. Even though all data will have the same store for now, you still want to receive it and process it so you can help leadership plan for possible future expansion to other stores and/or pickup locations.\n",
    "\n",
    "Assume today is October 4, 2020. The first day of sales was October 3, 2020. The JSON file came in very early this morning. As a data engineer, you need to get started with parsing, staging, validating, etc. the file as soon as possible.  \n",
    "\n",
    "The executives are anxious to understand how good the data is, if you will be able to continue withholding the customer data from Peak, and to get some preliminary analytics. Even though it's just one day's worth of data, the executives want as much information as soon as they can get it (which is very typical).\n",
    "\n",
    "The data science team has met with you, and together you came up with a plan to get the data loaded and validated, explore the customer data, and perform some preliminary analytics. The data science team has been requested to give the executives an assessment of the customer data and whether or not they should continue to withhold customer data from Peak. Since you are going to be the first one to have an extensive look at the data, the data science team wants and values your opinion on the customer data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c6e20e",
   "metadata": {},
   "source": [
    "# Included Modules and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "530d745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91c8869",
   "metadata": {},
   "source": [
    "# Additional Setup Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e09ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run a select query and return rows in a pandas dataframe\n",
    "# Note: pandas formats all numeric values from postgres as float\n",
    "\n",
    "def my_select_query_pandas(query, rollback_before_flag, rollback_after_flag):\n",
    "    \"Function to run a select query and return rows in a pandas dataframe\"\n",
    "    \n",
    "    if rollback_before_flag:\n",
    "        connection.rollback()\n",
    "    \n",
    "    df = pd.read_sql_query(query, connection)\n",
    "    \n",
    "    if rollback_after_flag:\n",
    "        connection.rollback()\n",
    "    \n",
    "    # Fix any float columns that really should be integers\n",
    "    \n",
    "    for column in df:\n",
    "    \n",
    "        if df[column].dtype == \"float64\":\n",
    "\n",
    "            fraction_flag = False\n",
    "\n",
    "            for value in df[column].values:\n",
    "                \n",
    "                if not np.isnan(value):\n",
    "                    if value - math.floor(value) != 0:\n",
    "                        fraction_flag = True\n",
    "\n",
    "            if not fraction_flag:\n",
    "                df[column] = df[column].astype('Int64')\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f198d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up connection to postgres\n",
    "# Note: All connection inputs below have been removed for protection\n",
    "connection = psycopg2.connect(\n",
    "    user = \"\",\n",
    "    password = \"\",\n",
    "    host = \"\",\n",
    "    port = \"\",\n",
    "    database = \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7a762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d7ad400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read a csv file and print a set number of rows\n",
    "\n",
    "def my_read_csv_file(file_name, limit):\n",
    "    \"Read the csv file and print only the first 'limit' rows\"\n",
    "    \n",
    "    csv_file = open(file_name, \"r\")\n",
    "    \n",
    "    csv_data = csv.reader(csv_file)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for row in csv_data:\n",
    "        i += 1\n",
    "        if i <= limit:\n",
    "            print(row)\n",
    "            \n",
    "    print(\"\\nPrinted \", min(limit, i), \"lines of \", i, \"total lines.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e6beed",
   "metadata": {},
   "source": [
    "# 2.1.1 Drop the product mapping table if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d30a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query drops the product mapping table if it already exists\n",
    "\n",
    "connection.rollback()\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "drop table if exists peak_product_mapping;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query)\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c605bc0",
   "metadata": {},
   "source": [
    "# 2.1.2 Create the product mapping table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23f9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query creates the structure of the product mapping table\n",
    "\n",
    "connection.rollback()\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "create table peak_product_mapping (\n",
    "  product_id numeric(3),\n",
    "  peak_product_id numeric(12),\n",
    "  primary key (product_id)\n",
    ");\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query)\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35e95b4",
   "metadata": {},
   "source": [
    "# 2.1.3 Create a CSV file of product mapping data and display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daabc6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['product_id', 'peak_product_id']\n",
      "['1', '42314677']\n",
      "['2', '42314678']\n",
      "['3', '42314679']\n",
      "['4', '42314780']\n",
      "['5', '42314781']\n",
      "['6', '42314782']\n",
      "['7', '42314783']\n",
      "['8', '42314784']\n",
      "\n",
      "Printed  9 lines of  9 total lines.\n"
     ]
    }
   ],
   "source": [
    "# Creates dataframe for .csv file\n",
    "mapping_data = {\n",
    "    \"product_id\":      [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    \"peak_product_id\": [42314677, 42314678, 42314679, 42314780, 42314781, 42314782, 42314783, 42314784]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(mapping_data)\n",
    "\n",
    "# Converts dataframe to .csv file\n",
    "df.to_csv(\"peak_product_mapping.csv\", index = False)\n",
    "\n",
    "# Reads/displays .csv file\n",
    "my_read_csv_file(\"peak_product_mapping.csv\", limit = 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31ed590",
   "metadata": {},
   "source": [
    "# 2.1.4 Load product mapping data into database table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "481c947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query loads .csv file with product mapping data into product mapping table\n",
    "\n",
    "connection.rollback()\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "copy peak_product_mapping\n",
    "from '/user/projects/project-2-ethanjmoody/peak_product_mapping.csv' delimiter ',' NULL '' csv header;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query)\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f844d1e",
   "metadata": {},
   "source": [
    "# 2.1.5 Verify the product mapping loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28ad8dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>peak_product_id</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>42314677</td>\n",
       "      <td>Pistachio Salmon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>42314678</td>\n",
       "      <td>Teriyaki Chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>42314679</td>\n",
       "      <td>Spinach Orzo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>42314780</td>\n",
       "      <td>Eggplant Lasagna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42314781</td>\n",
       "      <td>Chicken Salad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>42314782</td>\n",
       "      <td>Curry Chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>42314783</td>\n",
       "      <td>Tilapia Piccata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>42314784</td>\n",
       "      <td>Brocolli Stir Fry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  peak_product_id       product_name\n",
       "0           1         42314677   Pistachio Salmon\n",
       "1           2         42314678   Teriyaki Chicken\n",
       "2           3         42314679       Spinach Orzo\n",
       "3           4         42314780   Eggplant Lasagna\n",
       "4           5         42314781      Chicken Salad\n",
       "5           6         42314782      Curry Chicken\n",
       "6           7         42314783    Tilapia Piccata\n",
       "7           8         42314784  Brocolli Stir Fry"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query returns products by AGM's product id and Peak's product id based on product mapping table\n",
    "\n",
    "rollback_before_flag = True\n",
    "rollback_after_flag = True\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "select\n",
    "  t1_map.*\n",
    ", t2_products.description as product_name\n",
    "  \n",
    "from peak_product_mapping as t1_map\n",
    "\n",
    "join products as t2_products\n",
    "on t1_map.product_id = t2_products.product_id\n",
    "\n",
    "order by\n",
    "  t1_map.product_id\n",
    "\n",
    ";\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "my_select_query_pandas(query, rollback_before_flag, rollback_after_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85fb798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
